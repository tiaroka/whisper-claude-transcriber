# 音声文字起こしシステム

音声・動画ファイルから高品質な文字起こしを生成するシステムです。OpenAIのWhisperモデルとAnthropicのClaudeモデルを組み合わせて使用し、正確で読みやすい文字起こしを実現します。

## 機能

- 様々な音声・動画フォーマットに対応（MP3, WAV, MP4, AVI, MOV, M4A, AAC）
- 長時間の音声ファイルを自動分割
- OpenAI Whisperによる高精度な音声認識
- Claude AIによる文字起こし結果の整形・修正
- タイムスタンプの自動生成と集約
- Google Colab環境とローカル環境の両方に対応

## システム要件

- Python 3.8以上
- FFmpeg（音声・動画ファイルの処理に必要）
- OpenAI API キー（Whisper文字起こし用）
- Anthropic API キー（Claude後処理用）

## インストール方法

1. リポジトリをクローンまたはダウンロードします。

2. 必要なパッケージをインストールします。

```bash
pip install pydub openai anthropic moviepy tqdm chardet python-dotenv
```

3. FFmpegをインストールします。

- Windows: `choco install ffmpeg`
- Mac: `brew install ffmpeg`
- Linux: `apt-get install ffmpeg`

4. APIキーを設定します。

`.env`ファイルをプロジェクトのルートディレクトリに作成し、以下の内容を記述します。

```
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
```

または環境変数として設定することもできます。

## 使用方法

このシステムは、ローカル環境とGoogle Colab環境の両方で利用できます。

### ローカル環境での使用方法

1. 入力ディレクトリに処理したい音声・動画ファイルを配置します。
   - デフォルトでは `input` ディレクトリが使用されます。

2. プログラムを実行します。
   ```bash
   # 標準版の場合
   python audio_transcriber_202502.py
   
   # 並列処理版の場合
   python audio_transcriber_parallel.py
   ```

3. 並列処理版を使用する場合は、ワーカー数の入力を求められます。
   - デフォルトではシステムのCPUコア数が使用されます。
   - 空欄のままEnterを押すとデフォルト値が使用されます。

4. メニューから実行したい処理を選択します。
   - **1**: 音声ファイルのエンコードと分割
   - **2**: 音声からテキストへの変換
   - **3**: Claudeによる文字起こし後処理
   - **4**: 全ての処理を順番に実行
   - **0**: 終了

5. 処理が完了すると、結果が `output` ディレクトリに保存されます。

### Google Colabでの使用方法

1. `colab-notebook.ipynb`をGoogle Colabで開きます。
   - GitHubからノートブックを直接開く場合: [Open in Colab]ボタンをクリックします。
   - ローカルからアップロードする場合: Google Colabを開き、[ファイル] > [ノートブックをアップロード]を選択します。

2. ノートブック内のセルを順番に実行します：
   - 必要なライブラリのインストール
   - Google Driveのマウント
   - 必要なモジュールのダウンロード
   - 互換性モジュールの作成

3. APIキーを設定します（以下のいずれかの方法）：
   - Google Cloud Secret Managerを使用
   - プロンプトに従って直接入力
   - コード内で直接設定

4. 処理したい音声・動画ファイルをGoogle Driveの指定フォルダにアップロードします。
   - デフォルトのパス: `/content/drive/MyDrive/開発/Whisper/Input`

5. 「プログラム実行」セルを実行し、メニューから処理を選択します。
   - 並列処理のワーカー数を指定するプロンプトが表示されたら、希望する数値を入力します。

6. 処理が完了すると、結果ファイルはGoogle Driveの出力フォルダに保存されます。
   - デフォルトのパス: `/content/drive/MyDrive/開発/Whisper/Output`

### 標準版と並列版の違い

本プロジェクトには2つのバージョンの文字起こしスクリプトが含まれています：

1. **audio_transcriber_202502.py（標準版）**:
   - 単一スレッドで処理を行います。
   - メモリ使用量が少なく、リソースの制約がある環境に適しています。
   - 処理速度よりも安定性を重視する場合に適しています。

2. **audio_transcriber_parallel.py（並列版）**:
   - ThreadPoolExecutorを使用した並列処理を実装しています。
   - 複数のファイルを同時に処理することで、処理速度が大幅に向上します。
   - ワーカー数を指定して、CPU使用率を調整できます。
   - 大量のファイルを処理する場合や、高速な処理が必要な場合に適しています。

使用する環境やニーズに応じて、適切なバージョンを選択してください。

## モジュール構成

システムは以下のモジュールで構成されています：

1. **メインモジュール** (`audio_transcriber.py`)
   - メイン関数と実行フロー制御
   - コマンドラインインターフェース
   - 各モジュールの統合

2. **互換性モジュール** (`compatibility.py`)
   - Colab/ローカル環境の互換性関数
   - 環境設定関連の機能
   - APIキー管理

3. **音声処理モジュール** (`audio_processing.py`)
   - 音声ファイルの変換・分割処理
   - TempDirectoryManager クラス
   - ファイル検出・処理機能

4. **文字起こしモジュール** (`transcription.py`)
   - AudioTranscriber クラス
   - Whisper による文字起こし機能
   - タイムコードに基づくテキスト分割

5. **後処理モジュール** (`post_processing.py`)
   - Claude による後処理機能
   - タイムスタンプ処理
   - ファイル結合・分割機能

6. **ユーティリティモジュール** (`utils.py`)
   - エンコーディング検出関数
   - ソート関数
   - その他の共通ユーティリティ

7. **設定モジュール** (`config.py`)
   - 定数定義
   - 設定値
   - 特記事項

## 処理フロー

1. **音源変換**: 様々な形式の音声・動画ファイルをMP3形式に変換
2. **音声分割**: 長い音声ファイルを処理しやすい長さに分割（デフォルト25分）
3. **文字起こし**: OpenAI Whisperを使用して音声をテキストに変換
4. **後処理**: Claude AIを使用して文字起こし結果を整形・修正
5. **結合**: 分割されたファイルを再結合して最終出力を生成

## 注意事項

- APIキーは安全に管理してください。
- 処理時間は音声の長さや品質によって異なります。
- 大きなファイルの処理にはメモリが必要です。
- APIの使用には料金が発生する場合があります。

## ライセンス

このプロジェクトはMITライセンスの下で公開されています。
