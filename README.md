# 音声文字起こしシステム

音声・動画ファイルから高品質な文字起こしを生成するシステムです。OpenAIのWhisperモデルとAnthropicのClaudeモデルを組み合わせて使用し、正確で読みやすい文字起こしを実現します。

## 機能

- 様々な音声・動画フォーマットに対応（MP3, WAV, MP4, AVI, MOV, M4A, AAC）
- 長時間の音声ファイルを自動分割
- OpenAI Whisperによる高精度な音声認識
- Claude AIによる文字起こし結果の整形・修正
- タイムスタンプの自動生成と集約
- Google Colab環境とローカル環境の両方に対応
- 日本語特化の重複検出・テキスト統合機能（最新版）
- 並列処理による高速化（設定可能なワーカー数）

## システム要件

- Python 3.8以上
- FFmpeg（音声・動画ファイルの処理に必要）
- OpenAI API キー（Whisper文字起こし用）
- Anthropic API キー（Claude後処理用）

## インストール方法

1. リポジトリをクローンまたはダウンロードします。

2. 必要なパッケージをインストールします。

```bash
pip install pydub openai anthropic moviepy tqdm chardet python-dotenv
```

3. FFmpegをインストールします。

- Windows: `choco install ffmpeg`
- Mac: `brew install ffmpeg`
- Linux: `apt-get install ffmpeg`

4. APIキーを設定します。

`.env`ファイルをプロジェクトのルートディレクトリに作成し、以下の内容を記述します。

```
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
```

または環境変数として設定することもできます。

## 使用方法

このシステムは、ローカル環境とGoogle Colab環境の両方で利用できます。

### ローカル環境での使用方法

1. 入力ディレクトリに処理したい音声・動画ファイルを配置します。
   - デフォルトでは `input` ディレクトリが使用されます。

2. プログラムを実行します。
   ```bash
   # 最新版（並列処理統合版）
   python audio_transcriber_202506.py
   
   # 旧版（標準版）
   python audio_transcriber_202502.py
   
   # 旧版（並列処理版）
   python audio_transcriber_parallel.py
   ```

3. メニューから実行したい処理を選択します。
   - **1**: 音声ファイルのエンコードと分割
   - **2**: 音声からテキストへの変換
   - **3**: 最適化フロー: Whisper → 日本語処理 → Claude（推奨）※最新版のみ
   - **4**: 日本語特化処理による高精度統合 ※最新版のみ
   - **5**: 全ての処理を順番に実行（推奨）
   - **6**: 並列処理設定の確認・変更 ※最新版のみ
   - **7**: 全般設定変更 ※最新版のみ
   - **0**: 終了

5. 処理が完了すると、結果が `output` ディレクトリに保存されます。

### Google Colabでの使用方法

1. `colab-notebook.ipynb`をGoogle Colabで開きます。
   - GitHubからノートブックを直接開く場合: [Open in Colab]ボタンをクリックします。
   - ローカルからアップロードする場合: Google Colabを開き、[ファイル] > [ノートブックをアップロード]を選択します。

2. ノートブック内のセルを順番に実行します：
   - 必要なライブラリのインストール
   - Google Driveのマウント
   - 必要なモジュールのダウンロード
   - 互換性モジュールの作成

3. APIキーを設定します（以下のいずれかの方法）：
   - Google Cloud Secret Managerを使用
   - プロンプトに従って直接入力
   - コード内で直接設定

4. 処理したい音声・動画ファイルをGoogle Driveの指定フォルダにアップロードします。
   - デフォルトのパス: `/content/drive/MyDrive/開発/Whisper/Input`

5. 「プログラム実行」セルを実行し、メニューから処理を選択します。

6. 処理が完了すると、結果ファイルはGoogle Driveの出力フォルダに保存されます。
   - デフォルトのパス: `/content/drive/MyDrive/開発/Whisper/Output`

### バージョンの違い

本プロジェクトには複数のバージョンの文字起こしスクリプトが含まれています：

1. **audio_transcriber_202506.py（最新版・推奨）**:
   - 標準版と並列版を統合し、ワーカー数を設定可能に
   - 日本語特化の重複検出・テキスト統合機能を実装
   - 最適化フロー: Whisper → 日本語処理 → Claude の新しい処理パイプライン
   - 設定ファイル（transcriber_config.json）による柔軟な設定が可能

2. **audio_transcriber_202502.py（旧標準版）**:
   - 単一スレッドで処理を行います
   - メモリ使用量が少なく、リソースの制約がある環境に適しています
   - 処理速度よりも安定性を重視する場合に適しています

3. **audio_transcriber_parallel.py（旧並列版）**:
   - ThreadPoolExecutorを使用した並列処理を実装しています
   - 複数のファイルを同時に処理することで、処理速度が向上します
   - ワーカー数を指定して、CPU使用率を調整できます

特別な理由がない限り、最新版（audio_transcriber_202506.py）の使用を推奨します。

## モジュール構成

最新版では以下のモジュールが含まれています：

1. **メインモジュール** (`audio_transcriber_202506.py`)
   - 統合版のメインプログラム
   - 並列処理機能を内包
   - 拡張されたメニューシステム

2. **日本語処理モジュール** (`japanese_text_processor.py`)
   - TypeScriptから移植された高度な日本語処理機能
   - レーベンシュタイン距離による類似度計算
   - 品質評価による重複除去
   - インテリジェントなテキストマージ

3. **互換性モジュール** (`colab_local_compatibility.py`)
   - Colab/ローカル環境の互換性関数
   - 環境設定関連の機能
   - APIキー管理

4. **設定管理モジュール** (`config.py`)
   - 対話的な設定管理システム
   - 設定の永続化機能

5. **設定ファイル** (`transcriber_config.json`)
   - 処理パラメータの設定
   - ワーカー数、言語設定、API設定など

## 処理フロー

### 従来のフロー（旧版）
1. **音源変換**: 様々な形式の音声・動画ファイルをMP3形式に変換
2. **音声分割**: 長い音声ファイルを処理しやすい長さに分割（デフォルト25分）
3. **文字起こし**: OpenAI Whisperを使用して音声をテキストに変換
4. **後処理**: Claude AIを使用して文字起こし結果を整形・修正
5. **結合**: 分割されたファイルを再結合して最終出力を生成

### 最適化フロー（最新版・推奨）
1. **音源変換**: 様々な形式の音声・動画ファイルをMP3形式に変換
2. **音声分割**: 長い音声ファイルを処理しやすい長さに分割（設定可能、デフォルト20分）
3. **文字起こし**: OpenAI Whisperを使用して音声をテキストに変換（VTT形式）
4. **日本語最適化処理**: 重複検出・除去、テキストマージ
5. **Claude処理**: バッチ処理による効率的な整形・修正
6. **最終出力**: 高品質な文字起こしファイルを生成

## 注意事項

- APIキーは安全に管理してください。
- 処理時間は音声の長さや品質によって異なります。
- 大きなファイルの処理にはメモリが必要です。
- APIの使用には料金が発生する場合があります。

## ライセンス

このプロジェクトはMITライセンスの下で公開されています。
